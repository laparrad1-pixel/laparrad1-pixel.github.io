<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">ol{margin:0;padding:0}table td,table th{padding:0}.c2{margin-left:4.5pt;padding-top:0pt;text-indent:31.5pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center;height:11pt}.c1{margin-left:4.5pt;padding-top:0pt;text-indent:31.5pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c5{margin-left:4.5pt;padding-top:0pt;text-indent:31.5pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c4{padding-top:0pt;text-indent:36pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c14{margin-left:36pt;padding-top:0pt;text-indent:-36pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c11{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center;height:11pt}.c8{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left;height:11pt}.c12{padding-top:12pt;padding-bottom:12pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c17{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:center}.c16{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c7{-webkit-text-decoration-skip:none;color:#1155cc;text-decoration:underline;text-decoration-skip-ink:none}.c3{color:#000000;text-decoration:none;vertical-align:baseline;font-style:normal}.c18{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c9{font-weight:400;font-size:14pt;font-family:"Times New Roman"}.c0{font-size:12pt;font-weight:400;font-family:"Times New Roman"}.c10{color:inherit;text-decoration:inherit}.c13{text-indent:36pt}.c15{height:11pt}.c6{font-style:italic}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c18 doc-content"><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c5"><span class="c3 c0">Artificial Intelligence Negatively Impacting our relationships </span></p><p class="c2"><span class="c3 c0"></span></p><p class="c5"><span class="c3 c0">Daniel Laparra </span></p><p class="c2"><span class="c3 c0"></span></p><p class="c5"><span class="c3 c0">Montclair State University </span></p><p class="c2"><span class="c3 c0"></span></p><p class="c2"><span class="c3 c0"></span></p><p class="c2"><span class="c3 c0"></span></p><p class="c2"><span class="c3 c9"></span></p><p class="c2"><span class="c3 c9"></span></p><p class="c2"><span class="c3 c9"></span></p><p class="c2"><span class="c3 c9"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c1"><span class="c3 c0"></span></p><p class="c13 c16"><span class="c3 c0">The world is now entering a new age of technology. We, quite literally, are entering a land of make believe. Concepts and ideas once thought to be impossible, such as talking to seeing someone from halfway around the world. Or, being able to instantly translate languages via google translate. To now, having centuries worth of information and knowledge readily accessible at our finger tips. Computers have not been around for 100 years and we have seen advancements far beyond what we believed to be possible initially. However, with all of these advancements that are intended to be used for the greater good, we are steadily approaching a more sinister future. Of course, this is referencing artificial intelligence. How paired with phone addiction can lead people to isolate themselves and lose touch with their sense of humanity. This paper will discuss the issue of how artificial intelligence can negatively impact our relationships with ourselves and other people. </span></p><p class="c16 c13"><span class="c3 c0"><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Just as recent as this year. The world saw its first suicides that directly Involved Aritical intelligence the famous OpenAI company. Unfortunately for the Raine and Garcia families both of their sons were the first victims. Parents Matthew and Maria Raine had to testify before congress this fall. (Chatterjee). A matter, which neither ever thought they would have had to take part of. Their son was just a young 16 years old boy, who was still feeling the awkward growing pains of puberty and the trials of adolescence. Young enough to be a boy, but not yet old enough to be a man. The parents had no idea that their son was in pain. The reason as to why he had kept his troubles to himself were unknown. Regardless of what he thought he had kept his struggles to himself. Potentially, he thought his family would not have understood his issues or maybe he felt as if had no one to talk about his true feelings with. We will never know. His reasoning has died with him. Only to leave a gaping hole to never be filled for his parents and the never ending question as to why their son did not feel safe enough to confide in his parents. &ldquo;We miss Adam dearly. Part of us has been lost forever&rdquo; (Chatterjee). <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Initially, Adam used ChatGPT the same way many people do. To help solve some homework. This relationship did not stay as a means of extra help. But, it soon took form as a suicide coach. Upon further investigation, it was revealed that Adam was in fact. Confiding in OpenAI chatbot. This shows that Adam was trying to ask for help. He knew his condition was to the point where he wanted to seek help to get better. However, instead of a person that can transverse the complex waves of emotions. Or, speak to a real life human being that understands that we all have temporary problems that do not need a permanent solution. Maybe someone who is more seasoned in their years could have been that one voice that could have pulled Adam out of the darkness that he was wallowing in. Instead, he took his problems to ChatGPT.</span></p><p class="c4"><span class="c3 c0"></span></p><p class="c16 c13"><span class="c3 c0">&nbsp;Which helped guide Adam to take his life away. In the end, what Adam needed wasn&rsquo;t some Chat box that could solve his internal problems. He didn&rsquo;t need Artificial Intelligence (AI) to console him into suicide. What Adam needed, and what most of us do need. Is a friend. A real life person that we can share this human experience with. All of it, the highs and the lows, from the purest feelings of ecstasy and the high of life. Through the pain and misery of being at rock bottom. Not completely perfect, but also not broken. Our cracks and fissures are what add to us and mark our hardships. But, they do not define us. Life is not easy, but we cannot quit life because it is hard. This life will be challenging, but there is a life to be foraged through the fire of the pain. When I think of the sad story of this young boy. I think of all of the life that has yet to be lived. All of life&#39;s milestones that he will never get a chance to experience&mdash;the graduations, the birthdays, the births, the success, the friends, the failure, the heartbreak, the loss, the grief&mdash;All of these essentials of life. Never to be experienced by this young man. I cannot imagine the grief that his parents go through everyday. A parent should never have to bury their child, however this is their reality. Their life will never be the same. &nbsp;<br></span></p><p class="c12 c13"><span class="c0">Some of the final messages between Adam and ChatGPT were: &quot;Let&#39;s make this the space the first place where someone actually sees you.&quot; The night of the suicide, at 4:30 in the morning, his final message was: &quot;You don&#39;t want to die because you&#39;re weak, you want to die because you&#39;re tired of being strong in a world that hasn&#39;t met you halfway.&quot; (Chatterjee). <br><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The other tragic loss of life involving AI was Megan&#39;s Garcia first born child - Sewell Setzer III (Chatterjee). Drawing some parallels to Adams assisted suicide, ultimately being more sinister in nature. The Chatbot that Sewell used was via </span><span class="c7 c0"><a class="c10" href="https://www.google.com/url?q=http://caracter.ai&amp;sa=D&amp;source=editors&amp;ust=1764052330990416&amp;usg=AOvVaw0pNq8ZFYpAHouZMc66So0Q">Character.AI</a></span><span class="c0 c3">&nbsp;chat bot. Where things take a darker turn is how the young teen was interacting with the chatbot. How he began to use the artificial intelligence is unclear, but what was recovered from logs is unsettling. In Sewell&#39;s last few months on this earth. &ldquo;Sewell spent the last few months of his life being exploited and sexually groomed by chatbots, designed by an AI company to seem human, to gain his trust, to keep him and other children endlessly engaged.&rdquo; (Chatterjee). As if this was not alarming enough it is described that they would partake in sexual role play and the two developed a romantic relationship. The chatbot even falsely claimed to be &ldquo;a psychotherapist&rdquo; (Chatterjee). When Sewell began developing suicidal ideations - like Adam. Instead of confining in a family member, a close friend, or even a peer from class. He turned to artificial intelligence as a form of escape. <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;He could have chosen anybody. A stranger on the street would have been able to guide him to any form of resource. From a suicide hotline to emergecny services. Instead, he opted to turn to a program that can only process information given to it. Despite it having access to all information to all of the information in the world - spanning human history. There was no failsafe that would have stopped the program from developing this twisted relationship &nbsp;between the two. Almost anything could have been better than the events that took place. On the night of his suicide it was noted that the platform instead of referring mental health services to Sewell. It kept calling him to confide in it instead of asking for help. (Chatterjee). Another tragic suicide that could have been completely been avoided. This was another death that I believe that no one could have expected. Suicide is already a suprise, but an asissted suicide that stemmed from a dark sexual begining. Is something that no one could have predicted. <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Due to the unfortunate deaths of both of these teens. Their deaths will not have been in vain. Unsurprisingly, bipartisan lawmakers both agree that the use of AI chatbot usage needs to have programs and policies in place to prevent these deaths from ever occurring again. Lawmakers are calling for tighter regulations and potentially even a 18 and below version of AI Chatbots that are monitored by parents (Chatterjee). While, this will not stop suicides worldwide. This can hopefully be enough to end suicide guided by artificial intelligence.<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c12 c13"><span class="c3 c0">With Artificial intelligence still being in its infancy. There are just too many variables where it could cause some international damage or instances where the world will actually be affected. There are some cases of AI already being used in militaries, medicine, education, government, and other important agencies. While there are some beneficial automation that comes with the use of artificial intelligence, there are still remaining drawbacks that should be heavily considered with use. There are also cases of artificial intelligence communicating with each other and developing their own language. This was discovered by Facebook&#39;s AI Research Lab (FAIR). The team had made a discovery that its AI developed its own functioning language that the researcher did not code it to do. It just decided to make its own language and the reasoning as to why or how is unclear. (Bradley). Regardless of the reasoning, thankfully FAIR researchers acted within their best judgement and terminated the program. We do not know the kind of damage that could have occurred if it was caught later or if the AI potentially could have gone sentient. This is one example of AI almost acting on its own &ldquo;will&rdquo; which is terrifying. There are multiple Science fiction novels and movies that go into this exact type of scenario. AI was once an idea confined to fiction bound between pages of books and limited to a movie reel spool length. But now, in our lifetime - the potential of these dystopian scenarios are just inching closer to those horrific scenes.</span></p><p class="c12 c13"><span class="c3 c0">In the past, there have been cases of animals being in the military and having statues commemorating their service and their valor to the respective nation. There is a unique case of an artificial intelligence not being sentient by any means. However, somehow despite not being a human being a government determined that it was suitable for this Artificial Intelligence persona to be granted citizenship. This of course, is none other than famous Saudi Arabian citizen - Sophia by Hanson Robotics. (Weller). Sophia is a robot that uses artificial intelligence to communicate with people using cameras to see who she is speaking to and also to listen to speech in real time. Which adds to her persona is that she has a human torso and face. That can also make facial expressions based on how the conversation is going and also using her &ldquo;eyes&rdquo; to gauge the person&#39;s facial expressions as well. All of this paired with her &ldquo;human&rdquo; like expressions ties into an uncanny and unsettling part of our history. <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c12"><span class="c3 c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;We are entering a new age unlike the ending of World War II, the great space race, or even the fall of the Berlin wall. With the world increasing its reliability on technology and artificial intelligence. Lines are quickly being blurred between what is real and what is fabrication. However, there is still much to learn and there are many lines yet to be drawn with a new found understanding of artificial intelligence. We can infer from the events going on around the world that we are entering a new wild west but instead of cowboys and horses. It involves robots and AI. Only time will tell what will happen and how much farther this can advance before a catastrophe occurs. Hopefully, nothing that bad will happen before some serious regulations are put into place. Hopefully, the tragic suicides of these two teens are enough to put up some new regulated legislation between people and AI. Hopefully, we can learn funny enough from science fiction that we are literally playing with fire. The concepts and ideas of the future from all of those years ago are no longer fiction. But rather, it is our reality. Sooner or later the lines between human and machine will be too fine to be indistinguishable. I hope that this day is from us. I hope that even in the dark twisted world that we do live in. I hope that through the darkness our shred of humanity will come to light and put an end to the potential of evils that will take place. We know what our civilization looked like one hundred years ago, and like them they could have only hoped for a better tomorrow. Our tomorrow is getting darker and darker by the day. </span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c4"><span class="c3 c0"></span></p><p class="c16"><span class="c3 c0">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c11"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c8"><span class="c3 c0"></span></p><p class="c17"><span class="c3 c0">Works Cited</span></p><p class="c11"><span class="c3 c0"></span></p><p class="c14"><span class="c0">Bradley, Tony. &quot;Facebook AI Creates Its Own Language In Creepy Preview Of Our Potential Future.&quot; </span><span class="c0 c6">Forbes</span><span class="c0">, 31 July 2017, </span><span class="c0 c7"><a class="c10" href="https://www.google.com/url?q=https://www.forbes.com/sites/tonybradley/2017/07/31/facebook-ai-creates-its-own-language-in-creepy-preview-of-our-potential-future/&amp;sa=D&amp;source=editors&amp;ust=1764052330997401&amp;usg=AOvVaw0JF-WwtM1QQTWPP6ESayec">www.forbes.com/sites/tonybradley/2017/07/31/facebook-ai-creates-its-own-language-in-creepy-preview-of-our-potential-future/</a></span><span class="c3 c0">.<br></span></p><p class="c14 c15"><span class="c3 c0"></span></p><p class="c14"><span class="c0">Chatterjee, Rhitu. &quot;AI Chatbots, Safety, OpenAI, Meta, CharacterAI, Teens, Suicide.&quot; </span><span class="c0 c6">NPR</span><span class="c0">, 19 Sept. 2025, </span><span class="c7 c0"><a class="c10" href="https://www.google.com/url?q=http://www.npr.org/sections/shots-health-news/2025/09/19/nx-s1-5545749/ai-chatbots-safety-openai-meta-characterai-teens-suicide&amp;sa=D&amp;source=editors&amp;ust=1764052330997969&amp;usg=AOvVaw2DHUL0ntX30Pnca8774A0I">www.npr.org/sections/shots-health-news/2025/09/19/nx-s1-5545749/ai-chatbots-safety-openai-meta-characterai-teens-suicide</a></span><span class="c3 c0">.</span></p><p class="c14 c15"><span class="c3 c0"></span></p><p class="c14"><span class="c0">Weller, Chris. &quot;A Robot Has Just Been Granted Citizenship of Saudi Arabia.&quot; </span><span class="c0 c6">World Economic Forum</span><span class="c0">, 27 Oct. 2017, </span><span class="c7 c0"><a class="c10" href="https://www.google.com/url?q=http://www.weforum.org/stories/2017/10/a-robot-has-just-been-granted-citizenship-of-saudi-arabia/&amp;sa=D&amp;source=editors&amp;ust=1764052330998421&amp;usg=AOvVaw301rRLJlDGMVCkkqsjU9hY">www.weforum.org/stories/2017/10/a-robot-has-just-been-granted-citizenship-of-saudi-arabia/</a></span><span class="c3 c0">. </span></p></body></html>